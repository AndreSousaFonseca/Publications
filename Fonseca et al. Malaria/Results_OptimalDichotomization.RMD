---
title: "Results_OptimalDichotomization.final.version"
author: "Andre"
date: '2022-12-14'
output:
  html_document:
    theme: united
    toc_depht: 4
    toc_float:
      collapsed: false 
      smoth_scroll: false
    toc: true
    code_download: true
    code_folding: hide
---


# specify script options
```{r}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)

```

# Load the required libraries & set seed
```{r}
# Load libraries:
library(MASS)             # Perform basic data analysis
library(dplyr)            # Better handle data
library(pROC)             # Perform an plot the ROC curve and obtain the AIC  
library(tidyr)            # Better handle data
library(ggplot2)          # Plot the data
library(caret)            # Perform Confusion Matrices
library(doParallel)       # Use parallel processing for faster run times
library(OptimalCutpoints) # Obtain the optimal outpoints
library(SuperLearner)     # Perform predictive analysis
library(ggrepel)          # Avoid overlapping text in graph
set.seed(42)              # Specify a seed
```


# Specify the number of cores for parallel processing
```{r}
# Specify the number of cores
numCores <- detectCores()
registerDoParallel(numCores)  # use multicore, set to the number of our cores
```


# Load and pre-process the data
```{r}
# Load the data
KEN <- read.csv("KEN.csv", header=T, check.names=FALSE)

# Attribute subject id to rownames
rownames(KEN) <- KEN$SubjectID

# select only patients with parasite at screening
my.data <- subset(KEN, KEN$ParasiteAtScreen==1)

# Ignore variables that were not used in the original paper
ignore <- c("SubjectID","NEpisodes","TimeToFirstEpisode", "ParasiteAtScreen", "Age", "SchizontReactivity", "Status")

# Specify the predictive variables
X <- my.data[, !colnames(my.data) %in% ignore] 

# Specify the outcome variable
Y <- data.frame( "Status" = my.data[, colnames(my.data) %in% "Status"]); rownames(Y) <- my.data$SubjectID
```

# Perform the alogrithm for the chi-squared test
```{r}
f.pval <- data.frame()                        # Data.frame to store p.values from single antibody
all.pval <- data.frame()                      # Data.frame to store best p.value fo each antibody
sens_spe.vals <-  data.frame()                # Dataf.rame to store sensitivity and specificity values
new.data <-  data.frame("Status" = Y$Status)  # Data.frame to store the dichotomized values

# Function with the algorithm itself
for (i in 1:ncol(X)) {
  ab <- X[,i]   # Define column (antibody)
  
  for (j in 1:length(ab)) {   # For each value of the antibody:
    trs <-  ab[j]             # Define the antibody value as a threshold
    ss <- ifelse(ab > trs, "Seropositive", "Seronegative") # Patients with Values above the treshold are sero +  and below sero -
    tab <- table(ss, Y$Status)  # Obtain the number of individuals for each class
    
    if( nrow(tab) < 2 | ncol(tab) <2 ){ # Put every important value into a dataframe
      p.val <- data.frame("p.value"= NA, "threshold" = trs, "Seronegative" = table(ss)[1], "Seropositive" = table(ss)[2], "Seropositivity" = (table(ss)[2])/121 )
    }else{
     p.val <- data.frame("p.value"= chisq.test(tab)$p.value, "threshold" =trs, "Seronegative"= table(ss)[1], "Seropositive" = table(ss)[2],"Seropositivity" = (table(ss)[2])/121)
    }
    f.pval <- rbind(f.pval, p.val)  # Bind the above information for every possible threshold
    
  }
  b.pval <- f.pval[which.min(f.pval$p.value),]    # Select the threshold for which the p-value is lowest ( higher discriminatory power)
  all.pval <- rbind(all.pval, b.pval)             # Bind this information together
  new.val <-  ifelse(ab > b.pval$threshold, 1, 2) # Dichotomize the data
  new.data <- cbind(new.data, new.val)            # Build the data.frame with the dichotomized values
  tab <- table(new.val, Y$Status)                 # Create a 2x2 table to obtain sensitivity and specificity
  sn.sp <- data.frame("Sensitivity" = tab[1]/sum(tab[,1]),
                      "Specificity" = tab[4]/sum(tab[,2])) # Get sensitivity and specificity
  sens_spe.vals <- rbind(sens_spe.vals, sn.sp)  # Bind everything on a data.frame
  
  f.pval <-  data.frame() # Clear the data.frame
  b.pval <- data.frame()  # Clear the data.frame
}

# Attirbute the respective col/rownames
rownames(all.pval) <- colnames(X)
colnames(new.data)[2:ncol(new.data)] <- colnames(X)
rownames(sens_spe.vals) <-  colnames(X)
```

# Plot the p-value data
```{r}
# Gather the useafull information to be plotted
p.vals <-  data.frame("Antibody" = rownames(all.pval),
                          "p.value" = all.pval$p.value,
                          "Significance" = ifelse(all.pval$p.value <0.05, "Significant","Not significant"))


# Function to simulate default R plot
theme_new <- function(base_size = 12, base_family = "Helvetica"){
  theme_bw(base_size = base_size, base_family = base_family) %+replace%
    theme(
      #line = element_line(colour="black"),
      #text = element_text(colour="black"),
      axis.title = element_text(size = 14),
      #axis.text = element_text(colour="black", size=8),
      #strip.text = element_text(size=12),
      legend.key=element_rect(colour=NA, fill =NA),
      panel.grid = element_blank(),   
      panel.border = element_rect(fill = NA, colour = "black", size=1),
      panel.background = element_rect(fill = "white", colour = "black"), 
      strip.background = element_rect(fill = NA),
      axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
      legend.position = c(0.93, 0.12),
      legend.background = element_rect(size=0.5, linetype="solid")
    )
}

# Plot
ggplot(p.vals, aes(x=Antibody, y=log10(p.value),fill = Significance)) +
  geom_point(shape = 21 ,size = 4) + 
  scale_fill_manual(values=c("blue", "salmon")) +
  geom_hline(yintercept = log10(0.05), lty=2, col = "black") +
  coord_cartesian( ylim = c(-7, 0)) +
  scale_y_continuous( breaks = c( 0, -1,-2,-3,-4,-5, -6, -7), labels= c(1, 0.1, 0.01, 0.001 , 0.0001, 0.00001, 0.000001, 0.0000001)) +
  theme_new() +
  ylab("p.value") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), axis.text=element_text(size=15))
#1200 x 585 px
```


# Plot the sensitivity against specificity scatter plot for each antibody
```{r}
# ADd a column called "Antibody" wih will have the Antibody names
sens_spe.vals$Antibody <-  rownames(sens_spe.vals)

# Plot the sensitivity against specificity scatter plot for each antibody
ggplot(sens_spe.vals, aes(1-Specificity, Sensitivity,  label=Antibody)) + geom_point(size= 3,alpha=0.7) + geom_text_repel(max.overlaps = 100) + theme_classic() + ylim(0,1) + xlim(0,1) + geom_abline(intercept = 0, slope = 1, col= "darkgrey", lty = 2) 
# 1200 x 715 px
  
# Gather the data to plot a ggplot2 barplot
ss.plot <-  gather(sens_spe.vals, "metric", "value", -Antibody)

# Plot
ggplot(ss.plot, aes(x= Antibody, y = value, fill=metric)) + 
  geom_bar(position="dodge", stat="identity", alpha =0.5)+  theme_test() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  ylim(0,1) 
```

# Perform p.value correction (Benjamini-Yekutieli)
```{r}
# Obtain the corrected p-values
p.values_ad <- p.adjust(all.pval$p.value, method = "BY", n=length(all.pval$p.value))

# Print the  number of significant antibodies after correction
print(paste("There are", sum(p.values_ad <0.05), "significant antibodies after Benjamini-Yekutieli correction"))

# Gather the information in a data.frame with the antibody names
adjusted.p <-  data.frame("Antibody" = rownames(all.pval),
                          "p.value" = p.values_ad,
                          "Significance" = ifelse(p.values_ad <0.05, "Significant","Not significant"))

# PLot
ggplot(adjusted.p , aes(x=Antibody, y=log10(p.value),fill = Significance)) +
  geom_point(shape = 21 ,size = 4) + 
  scale_fill_manual(values=c("blue", "salmon")) +
  geom_hline(yintercept = log10(0.05), lty=2, col = "black") +
  coord_cartesian( ylim = c(-7, 0)) +
  scale_y_continuous( breaks = c( 0, -1,-2,-3,-4,-5, -6, -7), labels= c(1, 0.1, 0.01, 0.001 , 0.0001, 0.00001, 0.000001, 0.0000001)) +
  theme_new() +
  ylab("p.value") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), axis.text=element_text(size=15))
#1200 x 585 px
```


# Subset in the dichotomized data the statsiticallty significant antibodies
```{r}
# Select only the statistically significant antibodies after correction
sig.abs <- subset(adjusted.p , adjusted.p$p.value <0.05)
dim(sig.abs)

# subset in the dichotomized (new.data) dataframe this significant antibodies
data <- new.data[, colnames(new.data) %in% sig.abs$Antibody]

# Transform the data from "1/2" to "1/0" to perform the SuperLEarner (Personal Preference)
for(i in 1:ncol(data)){
  data[,i] <-  ifelse(data[,i] == 1,1,0)
}

# Add the variable Status
data <- data.frame("Status" = Y$Status, data)
```


# Use the SuperLearner
We will perform Leave-one-out cross-validation, and a total of five models will be used:

- SL.glm

- SL.randomForest

- SL.xgboost

- SL.lda

- SL.qda

```{r}
x_train <- data[, !colnames(data) %in% "Status" ]
y_train <- ifelse(data$Status == "protected",1,0)

#write.csv(colnames(x_train), "opt_abs.csv")

# Implment the SuperLearner
set.seed(42)
sl = CV.SuperLearner(Y = y_train, X = x_train, family = binomial(),
                        V = nrow(x_train),
                        SL.library = c("SL.glm", "SL.randomForest","SL.lda", "SL.qda", "SL.xgboost"))

# Caching result
#saveRDS(sl, "sl_opt.RDS")
#sl<- readRDS("sl_opt.RDS")

# Review results.
summary(sl)
sl

#Obtain the weights
review_weights <- function(cv_sl) {
    meta_weights = coef(cv_sl)
    means = colMeans(meta_weights)
    sds = apply(meta_weights, MARGIN = 2,  FUN = sd)
    mins = apply(meta_weights, MARGIN = 2, FUN = min)
    maxs = apply(meta_weights, MARGIN = 2, FUN = max)
    sl_stats = cbind("mean(weight)" = means, "sd" = sds, "min" = mins, "max" = maxs)
    sl_stats[order(sl_stats[, 1], decreasing = TRUE), ]
}

# WEIGHTS
print(review_weights(sl), digits = 3)

# Obtain the roc curve 
roc <- roc(y_train , sl$SL.predict)
print(roc)

# Obtain the cut-offs
X <- data.frame("X"= sl$SL.predict, "Y" = y_train )

# Obtain the optimal cutpoints (point closest to the top left and sensitivity = specificity)
opt.roc01 <- optimal.cutpoints("X", "Y", tag.healthy = 0, method = "ROC01" , data = X)
opt.spse <- optimal.cutpoints("X", "Y", tag.healthy = 0, method = "SpEqualSe", data = X)

print("ROC01")
print(summary(opt.roc01))

print("SpEqualSe")
print(summary(opt.spse))

#Obtain the summary
s.roc01 <- summary(opt.roc01) 
s.sesp <- summary(opt.spse)   

# Obtain the thresold point
t.roc01 <- s.roc01$p.table$Global$ROC01[[1]][1]
t.sesp <- s.sesp$p.table$Global$SpEqualSe[[1]][1]


#PLot in the roc curve
plot(roc, legacy.axes = T )

#PLot the points
points(x= s.roc01$p.table$Global$ROC01[[1]][3], y=s.roc01$p.table$Global$ROC01[[1]][2], col ="#F8766D", pch = 19, cex=1.5)
text(x=s.roc01$p.table$Global$ROC01[[1]][3] + 0.1, y =s.roc01$p.table$Global$ROC01[[1]][2] +0.05, paste("ROC01:",round(s.roc01$p.table$Global$ROC01[[1]][1],3)), col= "#F8766D")

points(x= s.sesp$p.table$Global$SpEqualSe[[1]][3], y=s.sesp$p.table$Global$SpEqualSe[[1]][2], col ="#619CFF", pch = 19, cex=1.5)
text(x=s.sesp$p.table$Global$SpEqualSe[[1]][3] - 0.20, y =s.sesp$p.table$Global$SpEqualSe[[1]][2] -0.01, paste("SpEqualSe:",round(s.sesp$p.table$Global$SpEqualSe[[1]][1],3)), col= "#619CFF")
# 600 x 600 px
```


# Obtain classification labels
```{r}
sl_loo_roc01_labels <- ifelse(sl$SL.predict >= t.roc01 , 1, 0)
sl_loo_sesp_labels <- ifelse(sl$SL.predict >= t.sesp , 1, 0)

#Plot confusion matrix for "ROC01"
cf <- confusionMatrix( as.factor(sl_loo_roc01_labels), as.factor(y_train), positive = "1")$table
tb <- matrix(data =c(cf[4],cf[3],cf[2],cf[1]), 2)
fourfoldplot(tb, color = c("#FFCCCC", "#F8766D"),
             conf.level = 0,std ="ind.max")

#Plot confusion matrix for "SpEqualSe"
cf2 <-confusionMatrix(as.factor(sl_loo_sesp_labels), as.factor(y_train),positive = "1")$table
tb <- matrix(data =c(cf2[4],cf2[3],cf2[2],cf2[1]), 2)
fourfoldplot(tb, color = c("#CCFFFF", "#00BFC4"),
             conf.level = 0,std ="ind.max")
```

# Obtain the model metrics according to the 'ROC01' threshold
```{r}
# Remove the qda column because it was all NA
library.pred <-  sl$library.predict[,-4]

# Obtain the metrics for each model
measure_individual_performance <- function(sl){
    output_list <- list()
    for(i in 1:ncol(library.pred)){
        prediction_vector <- library.pred[, i] # Obtain the predictive values fore each model
        prediction_labels <- ifelse(prediction_vector > s.roc01$p.table$Global$ROC01[[1]][1], 1, 0)
        conf <- caret::confusionMatrix(data = factor(prediction_labels, levels = c(1, 0)),
                                           reference = factor(y_train, levels = c(1, 0)),
                                           mode = 'everything',
                                           positive = "1")
        sl_roc <- roc(y_train~prediction_vector)
        metrics <- c(
            AUC = sl_roc$auc[1],
            conf$overall[1],
            conf$byClass["Sensitivity"],
            conf$byClass["Specificity"],
            conf$byClass["Precision"],
            conf$byClass["Recall"],
            conf$byClass["F1"]
        )
        output_list[colnames(library.pred)[i]] <- list(metrics)
    }
    output_list
}
print("For the 'ROC01' metric the results are the following:")
print(data.frame(measure_individual_performance(sl)))
```

# Obtain model metrics according to hte 'SpEqualSe' threshold
```{r}
measure_individual_performance <- function(sl){
    output_list <- list()
    for(i in 1:ncol(library.pred)){
        prediction_vector <- library.pred[, i] # Obtain the predictive values fore each model
        prediction_labels <- ifelse(prediction_vector > s.sesp$p.table$Global$SpEqualSe[[1]][1], 1, 0)
        conf <- caret::confusionMatrix(data = factor(prediction_labels, levels = c(1, 0)),
                                           reference = factor(y_train, levels = c(1, 0)),
                                           mode = 'everything',
                                           positive = "1")
        sl_roc <- roc(y_train~prediction_vector)
        metrics <- c(
            AUC = sl_roc$auc[1],
            conf$overall[1],
            conf$byClass["Sensitivity"],
            conf$byClass["Specificity"],
            conf$byClass["Precision"],
            conf$byClass["Recall"],
            conf$byClass["F1"]
        )
        output_list[colnames(sl$library.predict)[i]] <- list(metrics)
    }
    output_list
}
print("For the 'SpEqualSe' metric the results are the following:")
print(data.frame(measure_individual_performance(sl)))
```

Validation using Random Forest
```{r}
library(caret)
train.control <- trainControl(method='repeatedcv', 
                        number=10, 
                        repeats=10)


rf_default <- train(Status~., 
                      data=data , 
                      method='rf', 
                      metric='Accuracy',
                      trControl=train.control)

rf_default
rf_vimp <- varImp(rf_default, useModel = TRUE, scale=FALSE)
rf_vimp

rf_vimp <- varImp(rf_default, useModel = TRUE)
rf_vimp
```